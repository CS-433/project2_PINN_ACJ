{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## Hyperparameters tests"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["This notebook was written in order to find the combination of hidden layers $l$ and neurons $w$ that leads to the lowest error between the truth trajectories and the ones predicted by our PINN. Run every cell of this notebook in order to obtain the wanted results. The data used to for this notebook are on the same folder and can be found in the file 'k=50_L=7_N=5_M=1.csv'"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3277,"status":"ok","timestamp":1671484233033,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"Tc-rPcEIQCv9"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import torch\n","from scipy.integrate import solve_ivp\n","from torch import nn\n","import numpy as np\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671484234818,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"-WcNcQIMQIm7"},"outputs":[],"source":["X_SCALE = 3.0\n","V_SCALE = 50.0 * X_SCALE**2\n","F_SCALE = 30.0 # V_SCALE / X_SCALE\n","GRAD_F_SCALE = F_SCALE / X_SCALE"]},{"cell_type":"markdown","metadata":{"id":"3VYMsakwQK0P"},"source":["define ANN and losses"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1025,"status":"ok","timestamp":1671484237541,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"j_UQYIv5QMXw"},"outputs":[],"source":["from torch.autograd import grad\n","from functorch import vmap, vjp\n","from functorch import jacrev, jacfwd\n","\n","class NNApproximator(nn.Module):\n","  def __init__(self, dim_input = 6, dim_output = 2, num_hidden = 2, dim_hidden = 1, activation=nn.Tanh()):\n","    super().__init__()\n","\n","    self.dim_input = dim_input\n","\n","    self.layer_in = nn.Linear(4, dim_hidden)\n","    # self.layer_in = nn.Linear(dim_input, dim_hidden)\n","    self.layer_out = nn.Linear(dim_hidden, dim_output)\n","    self.k = nn.Parameter(torch.tensor(50.0, requires_grad=False))\n","\n","    num_middle = num_hidden - 1\n","    self.middle_layers = nn.ModuleList(\n","        [nn.Linear(dim_hidden, dim_hidden) for _ in range(num_middle)]\n","    )\n","    self.activation = activation\n","\n","  def forward(self, x):\n","    x_unit = x.reshape((-1,self.dim_input)) / X_SCALE\n","    s = torch.hstack((x_unit[:, 0:2] - x_unit[:, 2:4], x_unit[:, 4:6] - x_unit[:, 2:4]))\n","    out = self.activation(self.layer_in(s))\n","    for layer in self.middle_layers:\n","      out = self.activation(layer(out))\n","    return self.layer_out(out) * F_SCALE\n","\n","  def _get_force_truth(self, x):\n","    k = 50.0\n","    g = torch.tensor([[0.0, -9.81]])\n","    L0 = 5.0\n","    x1 = x[:,:2]\n","    x2 = x[:,2:4]\n","    x3 = x[:,4:]\n","    dx1 = x2 - x1\n","    dx2 = x3 - x2\n","    dx1_norm = torch.sqrt(torch.sum(dx1 ** 2, dim=1))[:,None]\n","    dx2_norm = torch.sqrt(torch.sum(dx2 ** 2, dim=1))[:,None]\n","    f1 = -k * (dx1_norm - L0) * (dx1 / dx1_norm)\n","    f2 = k * (dx2_norm - L0) * (dx2 / dx2_norm)\n","    F = f2\n","    F += g\n","    F += f1\n","    return F\n","  def jacobian(self, x):\n","    jac = vmap(jacrev(self.forward))\n","    return jac(x).squeeze()"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":824,"status":"ok","timestamp":1671484241021,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"8wVB7ypOpabk"},"outputs":[],"source":["def compute_data_loss_force(model, x_tr, y_tr):\n","  return 0.5 * torch.mean((model.forward(x_tr).flatten() - y_tr.flatten()) ** 2) / (F_SCALE ** 2)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1671484243027,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"pGMZrrs-pewn"},"outputs":[],"source":["def compute_PINN_loss(model, x, k):\n","    F_dot = model.jacobian(x)\n","    s1 = x[:, 0:2] - x[:, 2:4]\n","    s2 = x[:, 4:6] - x[:, 2:4]\n","\n","    s1 = s1 / torch.norm(s1, dim=1)[:, None]\n","    s2 = s2 / torch.norm(s2, dim=1)[:, None]\n","\n","    s1rot = s1 @ torch.from_numpy(np.array([[0, -1], [1, 0]]).T).float()\n","    s2rot = s2 @ torch.from_numpy(np.array([[0, -1], [1, 0]]).T).float()\n","\n","    f1_ax = torch.einsum('ij, ijk, ik->i', s1, F_dot[:, :, 0:2], s1) - k\n","    f2_ax = torch.einsum('ij, ijk, ik->i', s2, F_dot[:, :, 4:6], s2) - k\n","    f1_perp = torch.einsum('ij, ijk, ik->i', s1, F_dot[:, :, 0:2], s1rot)\n","    f2_perp = torch.einsum('ij, ijk, ik->i', s2, F_dot[:, :, 4:6], s2rot)\n","\n","    loss = (f1_ax ** 2).mean() + (f2_ax ** 2).mean()\n","    loss += (f1_perp ** 2).mean() + (f2_perp ** 2).mean()\n","\n","    return loss"]},{"cell_type":"markdown","metadata":{"id":"R6BvDPKUQUoA"},"source":["Load training data"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":433,"status":"ok","timestamp":1671484246366,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"L6ZuJAKzQVoT"},"outputs":[],"source":["import pandas as pd\n","\n","df = pd.read_csv('k=50_L=7_N=5_M=1.csv')\n","positions = df[['r0_x', 'r0_y', 'r1_x', 'r1_y', 'r2_x', 'r2_y', 'r3_x', 'r3_y','r4_x','r4_y']]\n","forces = df[['rddot1_x','rddot1_y','rddot2_x','rddot2_y','rddot3_x','rddot3_y']]\n","\n","position_stack = np.vstack((\n","    positions[['r0_x','r0_y','r1_x','r1_y','r2_x','r2_y']].to_numpy(),\n","    positions[['r1_x','r1_y','r2_x','r2_y','r3_x','r3_y']].to_numpy(),\n","    positions[['r2_x','r2_y','r3_x','r3_y','r4_x','r4_y']].to_numpy()\n","))\n","forces_stack = np.vstack((\n","    forces[['rddot1_x','rddot1_y']].to_numpy(),\n","    forces[['rddot2_x','rddot2_y']].to_numpy(),\n","    forces[['rddot3_x','rddot3_y']].to_numpy()\n","))\n","\n","x = torch.from_numpy(position_stack.copy()).float()\n","F = torch.from_numpy(forces_stack.copy()).float()"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1045,"status":"ok","timestamp":1671484249436,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"99b0K_mPQaTb"},"outputs":[],"source":["from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n","\n","def train_model(model, data_loss_fn, PINN_loss_fn, learning_rate=0.0001, max_epochs=1000, USE_BFGS=False, weight_decay=5e-5):\n","  model.train()\n","  tr_losses = []\n","  data_losses = []\n","  PINN_losses = []\n","\n","  # reference on torch.LBFGS usage\n","  # https://gist.github.com/tuelwer/0b52817e9b6251d940fd8e2921ec5e20\n","  # USE_BFGS = False\n","\n","  if USE_BFGS:\n","    optimizer = torch.optim.LBFGS(model.parameters())\n","    print(\"Using BFGS optimizer ... \")\n","    log_iter = 10\n","    def closure():\n","        optimizer.zero_grad()\n","        objective = data_loss_fn(model) + PINN_loss_fn(model)\n","        objective.backward()\n","        return objective\n","  else:\n","    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n","    print(\"Using Adam optimizer ... \")\n","    log_iter = 1000\n","\n","  # scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=3000, eta_min=1e-6)\n","  min_loss = 1e9\n","\n","  for epoch in range(max_epochs):\n","    data_loss = data_loss_fn(model)\n","    PINN_loss = PINN_loss_fn(model)\n","    loss = data_loss + PINN_loss\n","    if USE_BFGS:\n","      optimizer.step(closure)\n","    else:\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","    # scheduler.step()\n","\n","    if epoch % log_iter == 0:\n","      print(f\"Epoch: {epoch} - Loss: {float(loss):>7f} - Data: {float(data_loss):>7f} - PINN: {float(PINN_loss):>7f}\")\n","      print(f\"Loss over entire dataset: {float(compute_data_loss_force(model, x, F).detach()):>7f}\") # TODO: fix preprocess_x\n","    tr_losses.append(loss.detach().numpy())\n","    data_losses.append(data_loss.detach().numpy())\n","    PINN_losses.append(PINN_loss.detach().numpy())\n","\n","    if epoch > 2000 and loss.item() < 0.99 * min_loss:\n","    #   torch.save(model.state_dict(), 'checkpoint.pth')\n","      min_loss = loss.item()\n","\n","  #plt.semilogy(tr_losses, label=\"Total\")\n","  #plt.semilogy(data_losses, label=\"Data\")\n","  #plt.semilogy(PINN_losses, label=\"PINN\")\n","  #plt.legend()\n","\n","  print(\"Min loss: \", min_loss)\n","\n","  return model, np.array(tr_losses)"]},{"cell_type":"markdown","metadata":{"id":"-LabXbYmQleR"},"source":["Preparing training and collocation data"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484253514,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"YaKU94O1QoTc"},"outputs":[],"source":["class OracleModel(NNApproximator):\n","  def __init__(self):\n","    super().__init__()\n","\n","  def forward(self, x):\n","    return super()._get_force_truth(x)\n","\n","mdl_o = OracleModel()"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484255388,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"ePqlFbm7Qqri","outputId":"fdb6eb00-6aba-4a49-ae4a-98fe97fd0c46"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(0.3413)\n","tensor(0.3426)\n"]}],"source":["x_tr = torch.vstack((\n","    x[:500,:].clone(),\n","    x[2000:2500,:].clone(),\n","    x[4000:4500,:].clone()\n","))\n","y_tr = torch.vstack((\n","    F[:500,:].clone(),\n","    F[2000:2500,:].clone(),\n","    F[4000:4500,:].clone()\n","))\n","\n","print(compute_data_loss_force(mdl_o, x_tr, y_tr))\n","\n","x_tr += torch.randn_like(x_tr) * (torch.std(x_tr,dim=0) * 0.003)\n","\n","print(compute_data_loss_force(mdl_o, x_tr, y_tr))\n","\n","# sample_qmc = get_LHS_sample(x.detach(), 1024)\n","samples = x.detach().numpy() #np.vstack((sample_qmc, x_tr[:, :].detach()))\n","samples = torch.tensor(samples)\n","x_collocation = samples.float().requires_grad_(True)\n","\n","#print(compute_PINN_loss(mdl_o, x_collocation, 50))"]},{"cell_type":"markdown","metadata":{"id":"fMXoPsjBQ0QA"},"source":["Function to compute trajectories and forces"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484258660,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"4McllGbBQ5U8"},"outputs":[],"source":["def getqdot(x, xdot, model, xLeft, xRight):\n","    N_m = x.shape[0] // 2\n","\n","    x = np.concatenate((xLeft, x, xRight))\n","    forces = []\n","    for i in range(0, N_m):\n","        triplet = x[np.arange(2*i, 2*i + 6)]\n","        triplet = triplet[None,:]\n","        force = model.forward(torch.tensor(triplet).float())\n","        forces.append(force.detach().numpy())\n","\n","    forces = np.concatenate(forces).reshape(-1)\n","\n","    q0 = np.concatenate((x, xdot))\n","    qdot = np.concatenate((xdot, forces))\n","    return qdot\n","\n","def compute_trajectory(x0, x0dot, model, xLeft, xRight):\n","    N_m = x0.shape[0] // 2\n","    q0 = np.concatenate((x0, x0dot))\n","\n","    t0 = 0\n","    tf = 20\n","    Nt = 2000\n","    sol = solve_ivp(lambda t, q: getqdot(q[:2*N_m], q[2*N_m:], model, xLeft, xRight), [t0,tf], y0=q0, t_eval=np.linspace(t0, tf, Nt))\n","    y = sol.y\n","    t = sol.t\n","    return y, t"]},{"cell_type":"markdown","metadata":{"id":"HzINJT1XQ_Pp"},"source":["Initialize parameters for plotting "]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484261791,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"lnMLNoHURChS"},"outputs":[],"source":["# compute NN-predicted closed-loop trajectories\n","# modify as appropriate:\n","N_m = 5\n","xLeft  = (positions.iloc[0,:][['r0_x','r0_y']]).to_numpy()\n","xRight = (positions.iloc[0,:][['r4_x','r4_y']]).to_numpy()\n","mass_cols = ['r1_x','r1_y','r2_x','r2_y','r3_x','r3_y']\n","\n","# # the vector 'x0' contains the initial positions of the *movable* masses\n","# # i.e. x0.shape = [N_m * 2]\n","x0 = (positions.iloc[0,:][mass_cols]).to_numpy()\n","x0dot = np.zeros_like(x0)\n","\n","# to run: y, t = compute_trajectory(x0, x0dot, model, xLeft, xRight)"]},{"cell_type":"markdown","metadata":{"id":"4pkyPE5BRLUA"},"source":["function to compute error between truth trajectory and the predicted one at each axis"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":448,"status":"ok","timestamp":1671484264669,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"DQSt8qklRSK-"},"outputs":[],"source":["def mean_err_trajectory(y_true, y_pred):\n","  mass_cols = ['r1_x','r1_y','r2_x','r2_y','r3_x','r3_y']\n","  mean_err_x = []\n","  mean_err_y = []\n","  for i in range(6):\n","    err = (y_true[mass_cols[i]].to_numpy()-y_pred.T[:,i])**2\n","    mean_err_traj_i = (1/len(err))*np.sum(err)\n","    if i % 2 == 0:\n","       mean_err_x.append(mean_err_traj_i)\n","    else:\n","      mean_err_y.append(mean_err_traj_i)\n","  mean_err_x = np.asarray(mean_err_x)\n","  mean_err_y = np.asarray(mean_err_y)\n","  err_traj_x = (1/len(mean_err_x))*np.sum(mean_err_x)\n","  err_traj_y = (1/len(mean_err_y))*np.sum(mean_err_y)\n","  \n","  return err_traj_x, err_traj_y "]},{"cell_type":"markdown","metadata":{"id":"yTH_3_okSTnY"},"source":["function to compute the aforementioned error for a given model and number of times N"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":440,"status":"ok","timestamp":1671484269343,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"zEGpfd-sShan"},"outputs":[],"source":["def compute_err_trajectory_conf(model, N):\n"," err_traj_x = []\n"," err_traj_y = []\n"," for i in range(N):\n","   model_out, tr_losses = train_model(\n","    model,\n","    data_loss_fn=lambda model: 1e3*compute_data_loss_force(model, x_tr, y_tr),\n","    PINN_loss_fn=lambda model: 1e0*compute_PINN_loss(model, x_collocation, 50),\n","    learning_rate=lr,\n","    max_epochs=epoch,\n","    weight_decay=1e-3,\n","   )\n","   y_i, t_i = compute_trajectory(x0, x0dot, model_out, xLeft, xRight)\n","   err_traj_x_i, err_traj_y_i  = mean_err_trajectory(positions, y_i)\n","   err_traj_x.append(err_traj_x_i)\n","   err_traj_y.append(err_traj_y_i)\n","   \n","   \n","  \n"," err_traj_x = np.asarray(err_traj_x)\n"," err_traj_y = np.asarray(err_traj_y)\n"," \n"," \n","\n"," return np.mean(err_traj_x), np.mean(err_traj_y), np.std(err_traj_x), np.std(err_traj_y)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VZxmky6FRW0F"},"source":["training NN"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":453,"status":"ok","timestamp":1671484272641,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"N3OJcbFGRYA4"},"outputs":[],"source":["#initialize parameters \n","num_layer = np.array([3, 5, 7])\n","hidden_dim = np.array([16, 32, 64])\n","epoch = 6000\n","lr = 9e-4\n","N = 5"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484274915,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"Bo4v1QuoRhCe"},"outputs":[],"source":["#create empty list that will be fill of mean squared err in x and y axis for each parameters combination\n","x_err_conf = []\n","y_err_conf = [] \n","\n","#create empty list that will be fill of the std in x and y axis for each parameters combination\n","x_std_conf = []\n","y_std_conf = [] "]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"Qodime1ld08c"},"source":["Given the possible value of hidden layers and neurons associated to the fact that we trained each model 5 times, it implies that we made 45 tests. This is really time and cost consuming especially with high number of hidden layers and neurons. To avoid those problems, we first decided to split the training in different cell marking by a subtitle refered to the configuration we use so that we are not in obligation to run everything in one time. Moreover, we bought 100 CPU in Google Colab for faster computation. \n","\n","This process was already done and the results were saved in the same folder in NPY format : \n","\n","- 'x_err_conf_multi_train.npy' : contains the MSE between the truth trajectories and the predicted ones in $\\hat{x}$ axis \n","- 'y_err_conf_multi_train.npy' : contains the MSE between the truth trajectories and the predicted ones in $\\hat{y}$ axis \n","- 'x_std_conf_multi_train.npy' : contains the std of the MSE computed in the file 'x_err_conf_multi_train.npy'\n","- 'y_std_conf_multi_train.npy' : contains the std of the MSE computed in the file 'y_err_conf_multi_train.npy'"]},{"cell_type":"markdown","metadata":{"id":"XvJUvj3wSEAB"},"source":["hidden layers = 3 and neurons = 16"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1671484277577,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"hzrZCqYTSGuT"},"outputs":[],"source":["#creating model \n","model_3_16 = NNApproximator(num_hidden=num_layer[0], dim_hidden=hidden_dim[0])"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538384,"status":"ok","timestamp":1671484829790,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"yJg5nudCWToV","outputId":"97125200-01b2-42a6-d3ed-ddef557b66d1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5059.267578 - Data: 56.455448 - PINN: 5002.812012\n","Loss over entire dataset: 0.054884\n","Epoch: 1000 - Loss: 5.720138 - Data: 3.635632 - PINN: 2.084506\n","Loss over entire dataset: 0.002489\n","Epoch: 2000 - Loss: 3.088752 - Data: 2.553238 - PINN: 0.535514\n","Loss over entire dataset: 0.001368\n","Epoch: 3000 - Loss: 1.689569 - Data: 1.548665 - PINN: 0.140904\n","Loss over entire dataset: 0.000335\n","Epoch: 4000 - Loss: 1.484839 - Data: 1.392528 - PINN: 0.092311\n","Loss over entire dataset: 0.000192\n","Epoch: 5000 - Loss: 1.399354 - Data: 1.330261 - PINN: 0.069092\n","Loss over entire dataset: 0.000143\n","Min loss:  1.31850004196167\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.308923 - Data: 1.257309 - PINN: 0.051614\n","Loss over entire dataset: 0.000426\n","Epoch: 1000 - Loss: 1.264019 - Data: 1.222247 - PINN: 0.041773\n","Loss over entire dataset: 0.000062\n","Epoch: 2000 - Loss: 1.202668 - Data: 1.168522 - PINN: 0.034145\n","Loss over entire dataset: 0.000045\n","Epoch: 3000 - Loss: 1.180052 - Data: 1.148491 - PINN: 0.031561\n","Loss over entire dataset: 0.000019\n","Epoch: 4000 - Loss: 1.200283 - Data: 1.170771 - PINN: 0.029512\n","Loss over entire dataset: 0.000040\n","Epoch: 5000 - Loss: 1.175671 - Data: 1.149323 - PINN: 0.026348\n","Loss over entire dataset: 0.000046\n","Min loss:  1.1697771549224854\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.158594 - Data: 1.135206 - PINN: 0.023388\n","Loss over entire dataset: 0.009970\n","Epoch: 1000 - Loss: 1.156538 - Data: 1.134226 - PINN: 0.022312\n","Loss over entire dataset: 0.000012\n","Epoch: 2000 - Loss: 1.153638 - Data: 1.132994 - PINN: 0.020644\n","Loss over entire dataset: 0.000011\n","Epoch: 3000 - Loss: 1.150809 - Data: 1.131945 - PINN: 0.018864\n","Loss over entire dataset: 0.000014\n","Epoch: 4000 - Loss: 1.155005 - Data: 1.137378 - PINN: 0.017627\n","Loss over entire dataset: 0.000008\n","Epoch: 5000 - Loss: 1.154747 - Data: 1.136796 - PINN: 0.017951\n","Loss over entire dataset: 0.000013\n","Min loss:  1.153807282447815\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.145910 - Data: 1.129932 - PINN: 0.015978\n","Loss over entire dataset: 0.006745\n","Epoch: 1000 - Loss: 1.145320 - Data: 1.129766 - PINN: 0.015554\n","Loss over entire dataset: 0.000012\n","Epoch: 2000 - Loss: 1.144529 - Data: 1.129449 - PINN: 0.015081\n","Loss over entire dataset: 0.000012\n","Epoch: 3000 - Loss: 1.143684 - Data: 1.129121 - PINN: 0.014563\n","Loss over entire dataset: 0.000012\n","Epoch: 4000 - Loss: 1.142832 - Data: 1.128691 - PINN: 0.014141\n","Loss over entire dataset: 0.000012\n","Epoch: 5000 - Loss: 1.143212 - Data: 1.129714 - PINN: 0.013498\n","Loss over entire dataset: 0.000009\n","Min loss:  1.1445281505584717\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.152200 - Data: 1.139079 - PINN: 0.013121\n","Loss over entire dataset: 0.009762\n","Epoch: 1000 - Loss: 1.142952 - Data: 1.128974 - PINN: 0.013978\n","Loss over entire dataset: 0.000016\n","Epoch: 2000 - Loss: 1.140314 - Data: 1.127571 - PINN: 0.012742\n","Loss over entire dataset: 0.000011\n","Epoch: 3000 - Loss: 1.139518 - Data: 1.127336 - PINN: 0.012182\n","Loss over entire dataset: 0.000011\n","Epoch: 4000 - Loss: 1.210765 - Data: 1.197120 - PINN: 0.013646\n","Loss over entire dataset: 0.000360\n","Epoch: 5000 - Loss: 1.138361 - Data: 1.126831 - PINN: 0.011530\n","Loss over entire dataset: 0.000011\n","Min loss:  1.1404173374176025\n"]}],"source":["err_traj_x_3_16, err_traj_y_3_16, std_traj_x_3_16, std_traj_y_3_16 = compute_err_trajectory_conf(model_3_16, N)"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":420,"status":"ok","timestamp":1671484870898,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"QMpyFEArikO3"},"outputs":[],"source":["x_err_conf.append(err_traj_x_3_16)\n","y_err_conf.append(err_traj_y_3_16)\n","x_std_conf.append(std_traj_x_3_16)\n","y_std_conf.append(std_traj_y_3_16)"]},{"cell_type":"markdown","metadata":{"id":"cjAfaZiEi1nu"},"source":["hidden layers = 3 and neurons = 32"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":539,"status":"ok","timestamp":1671484931301,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"SP-_-0S2i3yV"},"outputs":[],"source":["#creating model \n","model_3_32 = NNApproximator(num_hidden=num_layer[0], dim_hidden=hidden_dim[1])"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":576507,"status":"ok","timestamp":1671485509703,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"0ADhrb-ZjArw","outputId":"baf772e7-e76f-417a-f5f5-678e0b7c8643"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5018.904297 - Data: 13.054123 - PINN: 5005.850098\n","Loss over entire dataset: 0.012351\n","Epoch: 1000 - Loss: 4.076978 - Data: 3.484272 - PINN: 0.592706\n","Loss over entire dataset: 0.002336\n","Epoch: 2000 - Loss: 2.905474 - Data: 2.590789 - PINN: 0.314685\n","Loss over entire dataset: 0.001416\n","Epoch: 3000 - Loss: 1.641319 - Data: 1.458971 - PINN: 0.182348\n","Loss over entire dataset: 0.000258\n","Epoch: 4000 - Loss: 2.106978 - Data: 2.006055 - PINN: 0.100924\n","Loss over entire dataset: 0.000527\n","Epoch: 5000 - Loss: 1.313331 - Data: 1.249187 - PINN: 0.064145\n","Loss over entire dataset: 0.000077\n","Min loss:  1.269083857536316\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.299512 - Data: 1.245766 - PINN: 0.053745\n","Loss over entire dataset: 0.020878\n","Epoch: 1000 - Loss: 1.239695 - Data: 1.191824 - PINN: 0.047872\n","Loss over entire dataset: 0.000038\n","Epoch: 2000 - Loss: 1.213892 - Data: 1.172557 - PINN: 0.041335\n","Loss over entire dataset: 0.000028\n","Epoch: 3000 - Loss: 1.190012 - Data: 1.157054 - PINN: 0.032958\n","Loss over entire dataset: 0.000020\n","Epoch: 4000 - Loss: 1.170701 - Data: 1.146267 - PINN: 0.024434\n","Loss over entire dataset: 0.000016\n","Epoch: 5000 - Loss: 1.156969 - Data: 1.139016 - PINN: 0.017953\n","Loss over entire dataset: 0.000013\n","Min loss:  1.1538217067718506\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.150650 - Data: 1.136694 - PINN: 0.013956\n","Loss over entire dataset: 0.019310\n","Epoch: 1000 - Loss: 1.146472 - Data: 1.133674 - PINN: 0.012797\n","Loss over entire dataset: 0.000012\n","Epoch: 2000 - Loss: 1.143172 - Data: 1.131981 - PINN: 0.011191\n","Loss over entire dataset: 0.000012\n","Epoch: 3000 - Loss: 1.252971 - Data: 1.227798 - PINN: 0.025173\n","Loss over entire dataset: 0.000043\n","Epoch: 4000 - Loss: 1.144354 - Data: 1.135329 - PINN: 0.009025\n","Loss over entire dataset: 0.000011\n","Epoch: 5000 - Loss: 1.140314 - Data: 1.131721 - PINN: 0.008593\n","Loss over entire dataset: 0.000025\n","Min loss:  1.143168330192566\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.136666 - Data: 1.128710 - PINN: 0.007956\n","Loss over entire dataset: 0.021887\n","Epoch: 1000 - Loss: 1.135560 - Data: 1.127598 - PINN: 0.007962\n","Loss over entire dataset: 0.000010\n","Epoch: 2000 - Loss: 1.135286 - Data: 1.127682 - PINN: 0.007604\n","Loss over entire dataset: 0.000010\n","Epoch: 3000 - Loss: 1.135016 - Data: 1.127848 - PINN: 0.007168\n","Loss over entire dataset: 0.000015\n","Epoch: 4000 - Loss: 1.138674 - Data: 1.131491 - PINN: 0.007182\n","Loss over entire dataset: 0.000011\n","Epoch: 5000 - Loss: 1.145974 - Data: 1.136534 - PINN: 0.009440\n","Loss over entire dataset: 0.000020\n","Min loss:  1.1348278522491455\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.132114 - Data: 1.125489 - PINN: 0.006625\n","Loss over entire dataset: 0.029925\n","Epoch: 1000 - Loss: 1.131778 - Data: 1.125088 - PINN: 0.006691\n","Loss over entire dataset: 0.000010\n","Epoch: 2000 - Loss: 1.131462 - Data: 1.125121 - PINN: 0.006340\n","Loss over entire dataset: 0.000008\n","Epoch: 3000 - Loss: 1.134417 - Data: 1.128313 - PINN: 0.006104\n","Loss over entire dataset: 0.000023\n","Epoch: 4000 - Loss: 1.136272 - Data: 1.130245 - PINN: 0.006027\n","Loss over entire dataset: 0.000022\n","Epoch: 5000 - Loss: 1.134228 - Data: 1.128326 - PINN: 0.005902\n","Loss over entire dataset: 0.000011\n","Min loss:  1.132067322731018\n"]}],"source":["#training the PINN N times\n","err_traj_x_3_32, err_traj_y_3_32, std_traj_x_3_32, std_traj_y_3_32 = compute_err_trajectory_conf(model_3_32, N)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":408,"status":"ok","timestamp":1671485528608,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"jGEtAu6Pl9a4"},"outputs":[],"source":["x_err_conf.append(err_traj_x_3_32)\n","y_err_conf.append(err_traj_y_3_32)\n","x_std_conf.append(std_traj_x_3_32)\n","y_std_conf.append(std_traj_y_3_32)"]},{"cell_type":"markdown","metadata":{"id":"2HfcQtjKmHSR"},"source":["hidden layers = 3 and neurons = 64"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1671485578535,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"6WTTGPG4mIZ8"},"outputs":[],"source":["#creating model \n","model_3_64 = NNApproximator(num_hidden=num_layer[0], dim_hidden=hidden_dim[2])"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":823739,"status":"ok","timestamp":1671486405904,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"EkZMNlBemRmw","outputId":"4c576c48-71e8-4231-e94e-4d06de05a72b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5000.105469 - Data: 17.118092 - PINN: 4982.987305\n","Loss over entire dataset: 0.012006\n","Epoch: 1000 - Loss: 4.486187 - Data: 3.920775 - PINN: 0.565412\n","Loss over entire dataset: 0.002384\n","Epoch: 2000 - Loss: 1.569790 - Data: 1.385175 - PINN: 0.184615\n","Loss over entire dataset: 0.000200\n","Epoch: 3000 - Loss: 1.389145 - Data: 1.295832 - PINN: 0.093313\n","Loss over entire dataset: 0.000113\n","Epoch: 4000 - Loss: 1.315813 - Data: 1.245323 - PINN: 0.070490\n","Loss over entire dataset: 0.000084\n","Epoch: 5000 - Loss: 1.651981 - Data: 1.594893 - PINN: 0.057088\n","Loss over entire dataset: 0.000632\n","Min loss:  1.2340532541275024\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.228197 - Data: 1.180070 - PINN: 0.048128\n","Loss over entire dataset: 0.096822\n","Epoch: 1000 - Loss: 1.210476 - Data: 1.167373 - PINN: 0.043102\n","Loss over entire dataset: 0.000027\n","Epoch: 2000 - Loss: 1.190297 - Data: 1.155869 - PINN: 0.034428\n","Loss over entire dataset: 0.000021\n","Epoch: 3000 - Loss: 1.177518 - Data: 1.149303 - PINN: 0.028215\n","Loss over entire dataset: 0.000015\n","Epoch: 4000 - Loss: 1.167449 - Data: 1.144272 - PINN: 0.023177\n","Loss over entire dataset: 0.000018\n","Epoch: 5000 - Loss: 1.198269 - Data: 1.174517 - PINN: 0.023752\n","Loss over entire dataset: 0.000010\n","Min loss:  1.1665213108062744\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.215996 - Data: 1.196919 - PINN: 0.019077\n","Loss over entire dataset: 0.059330\n","Epoch: 1000 - Loss: 1.154344 - Data: 1.139080 - PINN: 0.015264\n","Loss over entire dataset: 0.000013\n","Epoch: 2000 - Loss: 1.175980 - Data: 1.162651 - PINN: 0.013329\n","Loss over entire dataset: 0.000025\n","Epoch: 3000 - Loss: 1.496161 - Data: 1.479424 - PINN: 0.016737\n","Loss over entire dataset: 0.000260\n","Epoch: 4000 - Loss: 1.420869 - Data: 1.388664 - PINN: 0.032204\n","Loss over entire dataset: 0.000276\n","Epoch: 5000 - Loss: 1.147032 - Data: 1.136200 - PINN: 0.010833\n","Loss over entire dataset: 0.000008\n","Min loss:  1.1466008424758911\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.154586 - Data: 1.141047 - PINN: 0.013539\n","Loss over entire dataset: 0.039689\n","Epoch: 1000 - Loss: 1.148251 - Data: 1.138167 - PINN: 0.010084\n","Loss over entire dataset: 0.000013\n","Epoch: 2000 - Loss: 1.143185 - Data: 1.133577 - PINN: 0.009608\n","Loss over entire dataset: 0.000012\n","Epoch: 3000 - Loss: 1.142213 - Data: 1.132986 - PINN: 0.009227\n","Loss over entire dataset: 0.000011\n","Epoch: 4000 - Loss: 1.141489 - Data: 1.132129 - PINN: 0.009360\n","Loss over entire dataset: 0.000009\n","Epoch: 5000 - Loss: 1.144416 - Data: 1.133167 - PINN: 0.011249\n","Loss over entire dataset: 0.000016\n","Min loss:  1.143182635307312\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.144665 - Data: 1.133720 - PINN: 0.010945\n","Loss over entire dataset: 0.037457\n","Epoch: 1000 - Loss: 1.221731 - Data: 1.212418 - PINN: 0.009313\n","Loss over entire dataset: 0.000007\n","Epoch: 2000 - Loss: 1.139174 - Data: 1.131553 - PINN: 0.007621\n","Loss over entire dataset: 0.000008\n","Epoch: 3000 - Loss: 1.137460 - Data: 1.129950 - PINN: 0.007510\n","Loss over entire dataset: 0.000008\n","Epoch: 4000 - Loss: 1.136021 - Data: 1.128872 - PINN: 0.007149\n","Loss over entire dataset: 0.000009\n","Epoch: 5000 - Loss: 1.198216 - Data: 1.185728 - PINN: 0.012487\n","Loss over entire dataset: 0.000118\n","Min loss:  1.1387144327163696\n"]}],"source":["#training the PINN N times\n","err_traj_x_3_64, err_traj_y_3_64, std_traj_x_3_64, std_traj_y_3_64 = compute_err_trajectory_conf(model_3_64, N)"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":1059,"status":"ok","timestamp":1671486430930,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"02F1kzf8q-m2"},"outputs":[],"source":["x_err_conf.append(err_traj_x_3_64)\n","y_err_conf.append(err_traj_y_3_64)\n","x_std_conf.append(std_traj_x_3_64)\n","y_std_conf.append(std_traj_y_3_64)"]},{"cell_type":"code","execution_count":29,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":434,"status":"ok","timestamp":1671486539273,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"9F2aspTEWzeJ","outputId":"4f2556c2-6fe9-4f80-f092-1a08e78a8b3e"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.0005777427089595671, 0.0011537579608421216, 0.0004304513503965368]\n","[0.008963260140918305, 0.00435669574964377, 0.011910312907729023]\n","[0.00017742125328560962, 0.00043612605815767605, 0.00016256329928062275]\n","[0.012287397742600894, 0.0014270595549179073, 0.013644463945017745]\n"]}],"source":["print(x_err_conf)\n","print(y_err_conf)\n","print(x_std_conf)\n","print(y_std_conf)"]},{"cell_type":"markdown","metadata":{"id":"Ph3Z2cN9rLgC"},"source":["hidden layers = 5 and neurons = 16"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":515,"status":"ok","timestamp":1671486575459,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"p8hQ68x3rNCa"},"outputs":[],"source":["#creating model \n","model_5_16 = NNApproximator(num_hidden=num_layer[1], dim_hidden=hidden_dim[0])"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":678012,"status":"ok","timestamp":1671487255826,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"W_2JIZIXrShL","outputId":"4acc1c86-babe-46c5-c532-6e9bee63ef8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5038.514648 - Data: 29.136618 - PINN: 5009.377930\n","Loss over entire dataset: 0.026851\n","Epoch: 1000 - Loss: 6.011778 - Data: 4.399876 - PINN: 1.611902\n","Loss over entire dataset: 0.003196\n","Epoch: 2000 - Loss: 4.321008 - Data: 3.726081 - PINN: 0.594927\n","Loss over entire dataset: 0.002495\n","Epoch: 3000 - Loss: 3.083440 - Data: 2.679244 - PINN: 0.404196\n","Loss over entire dataset: 0.001441\n","Epoch: 4000 - Loss: 1.815107 - Data: 1.616577 - PINN: 0.198530\n","Loss over entire dataset: 0.000397\n","Epoch: 5000 - Loss: 1.527137 - Data: 1.394936 - PINN: 0.132201\n","Loss over entire dataset: 0.000188\n","Min loss:  1.4369497299194336\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.473274 - Data: 1.373726 - PINN: 0.099548\n","Loss over entire dataset: 0.024355\n","Epoch: 1000 - Loss: 1.376534 - Data: 1.292475 - PINN: 0.084059\n","Loss over entire dataset: 0.000107\n","Epoch: 2000 - Loss: 1.318334 - Data: 1.247663 - PINN: 0.070671\n","Loss over entire dataset: 0.000074\n","Epoch: 3000 - Loss: 1.310336 - Data: 1.236931 - PINN: 0.073405\n","Loss over entire dataset: 0.000097\n","Epoch: 4000 - Loss: 1.257610 - Data: 1.197000 - PINN: 0.060610\n","Loss over entire dataset: 0.000042\n","Epoch: 5000 - Loss: 1.295726 - Data: 1.236704 - PINN: 0.059021\n","Loss over entire dataset: 0.000057\n","Min loss:  1.240638256072998\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.231845 - Data: 1.175543 - PINN: 0.056301\n","Loss over entire dataset: 0.036388\n","Epoch: 1000 - Loss: 1.227764 - Data: 1.171836 - PINN: 0.055928\n","Loss over entire dataset: 0.000031\n","Epoch: 2000 - Loss: 1.221335 - Data: 1.167042 - PINN: 0.054293\n","Loss over entire dataset: 0.000028\n","Epoch: 3000 - Loss: 1.214889 - Data: 1.162351 - PINN: 0.052538\n","Loss over entire dataset: 0.000028\n","Epoch: 4000 - Loss: 1.234052 - Data: 1.182005 - PINN: 0.052046\n","Loss over entire dataset: 0.000031\n","Epoch: 5000 - Loss: 1.220393 - Data: 1.168674 - PINN: 0.051719\n","Loss over entire dataset: 0.000043\n","Min loss:  1.2089359760284424\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.198812 - Data: 1.151102 - PINN: 0.047711\n","Loss over entire dataset: 0.018549\n","Epoch: 1000 - Loss: 1.195564 - Data: 1.149048 - PINN: 0.046516\n","Loss over entire dataset: 0.000019\n","Epoch: 2000 - Loss: 1.193326 - Data: 1.147304 - PINN: 0.046022\n","Loss over entire dataset: 0.000021\n","Epoch: 3000 - Loss: 1.205705 - Data: 1.160086 - PINN: 0.045619\n","Loss over entire dataset: 0.000026\n","Epoch: 4000 - Loss: 1.186679 - Data: 1.143539 - PINN: 0.043139\n","Loss over entire dataset: 0.000013\n","Epoch: 5000 - Loss: 1.212157 - Data: 1.165294 - PINN: 0.046862\n","Loss over entire dataset: 0.000055\n","Min loss:  1.1833226680755615\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.210339 - Data: 1.159098 - PINN: 0.051241\n","Loss over entire dataset: 0.024326\n","Epoch: 1000 - Loss: 1.179988 - Data: 1.139713 - PINN: 0.040274\n","Loss over entire dataset: 0.000014\n","Epoch: 2000 - Loss: 1.178069 - Data: 1.138563 - PINN: 0.039506\n","Loss over entire dataset: 0.000014\n","Epoch: 3000 - Loss: 1.212020 - Data: 1.160932 - PINN: 0.051088\n","Loss over entire dataset: 0.000042\n","Epoch: 4000 - Loss: 1.173916 - Data: 1.136488 - PINN: 0.037428\n","Loss over entire dataset: 0.000013\n","Epoch: 5000 - Loss: 1.547608 - Data: 1.413996 - PINN: 0.133612\n","Loss over entire dataset: 0.000346\n","Min loss:  1.178067684173584\n"]}],"source":["#training the PINN N times\n","err_traj_x_5_16, err_traj_y_5_16, std_traj_x_5_16, std_traj_y_5_16 = compute_err_trajectory_conf(model_5_16, N)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":512,"status":"ok","timestamp":1671487316844,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"y-ezuJF3twns"},"outputs":[],"source":["x_err_conf.append(err_traj_x_5_16)\n","y_err_conf.append(err_traj_y_5_16)\n","x_std_conf.append(std_traj_x_5_16)\n","y_std_conf.append(std_traj_y_5_16)"]},{"cell_type":"markdown","metadata":{"id":"TSWBreVct_A8"},"source":["hidden layers = 5 and neurons = 32"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":405,"status":"ok","timestamp":1671487357812,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"ddxRNAOyt_5I"},"outputs":[],"source":["#creating model \n","model_5_32 = NNApproximator(num_hidden=num_layer[1], dim_hidden=hidden_dim[1])"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":767358,"status":"ok","timestamp":1671488126666,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"amLu4ME8uDwC","outputId":"0f2e063c-8019-4d4d-eec1-ca6ae279cd37"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5012.019043 - Data: 16.959196 - PINN: 4995.060059\n","Loss over entire dataset: 0.015275\n","Epoch: 1000 - Loss: 6.593776 - Data: 5.793343 - PINN: 0.800433\n","Loss over entire dataset: 0.004783\n","Epoch: 2000 - Loss: 2.216938 - Data: 1.783142 - PINN: 0.433796\n","Loss over entire dataset: 0.000562\n","Epoch: 3000 - Loss: 1.668452 - Data: 1.452281 - PINN: 0.216171\n","Loss over entire dataset: 0.000246\n","Epoch: 4000 - Loss: 1.549940 - Data: 1.419111 - PINN: 0.130829\n","Loss over entire dataset: 0.000279\n","Epoch: 5000 - Loss: 1.451513 - Data: 1.353364 - PINN: 0.098149\n","Loss over entire dataset: 0.000168\n","Min loss:  1.3778395652770996\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.371909 - Data: 1.299018 - PINN: 0.072892\n","Loss over entire dataset: 0.109873\n","Epoch: 1000 - Loss: 1.328304 - Data: 1.266394 - PINN: 0.061910\n","Loss over entire dataset: 0.000108\n","Epoch: 2000 - Loss: 1.269018 - Data: 1.218840 - PINN: 0.050178\n","Loss over entire dataset: 0.000071\n","Epoch: 3000 - Loss: 1.233514 - Data: 1.191100 - PINN: 0.042414\n","Loss over entire dataset: 0.000053\n","Epoch: 4000 - Loss: 1.220245 - Data: 1.180864 - PINN: 0.039380\n","Loss over entire dataset: 0.000042\n","Epoch: 5000 - Loss: 1.194523 - Data: 1.158725 - PINN: 0.035798\n","Loss over entire dataset: 0.000028\n","Min loss:  1.194284200668335\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.184158 - Data: 1.150929 - PINN: 0.033229\n","Loss over entire dataset: 0.094735\n","Epoch: 1000 - Loss: 1.180617 - Data: 1.149093 - PINN: 0.031524\n","Loss over entire dataset: 0.000022\n","Epoch: 2000 - Loss: 1.186038 - Data: 1.154749 - PINN: 0.031289\n","Loss over entire dataset: 0.000049\n","Epoch: 3000 - Loss: 1.213170 - Data: 1.178850 - PINN: 0.034319\n","Loss over entire dataset: 0.000059\n","Epoch: 4000 - Loss: 1.168380 - Data: 1.141650 - PINN: 0.026730\n","Loss over entire dataset: 0.000017\n","Epoch: 5000 - Loss: 1.172456 - Data: 1.146945 - PINN: 0.025511\n","Loss over entire dataset: 0.000013\n","Min loss:  1.1656454801559448\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.218245 - Data: 1.192517 - PINN: 0.025728\n","Loss over entire dataset: 0.087217\n","Epoch: 1000 - Loss: 1.162574 - Data: 1.138846 - PINN: 0.023728\n","Loss over entire dataset: 0.000017\n","Epoch: 2000 - Loss: 1.229446 - Data: 1.193799 - PINN: 0.035647\n","Loss over entire dataset: 0.000018\n","Epoch: 3000 - Loss: 1.158461 - Data: 1.137528 - PINN: 0.020934\n","Loss over entire dataset: 0.000015\n","Epoch: 4000 - Loss: 1.156834 - Data: 1.136545 - PINN: 0.020289\n","Loss over entire dataset: 0.000015\n","Epoch: 5000 - Loss: 1.177188 - Data: 1.155180 - PINN: 0.022008\n","Loss over entire dataset: 0.000040\n","Min loss:  1.1649954319000244\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.153919 - Data: 1.135327 - PINN: 0.018592\n","Loss over entire dataset: 0.063760\n","Epoch: 1000 - Loss: 1.161967 - Data: 1.142929 - PINN: 0.019038\n","Loss over entire dataset: 0.000014\n","Epoch: 2000 - Loss: 1.152089 - Data: 1.134384 - PINN: 0.017705\n","Loss over entire dataset: 0.000014\n","Epoch: 3000 - Loss: 1.243071 - Data: 1.213861 - PINN: 0.029210\n","Loss over entire dataset: 0.000088\n","Epoch: 4000 - Loss: 1.149777 - Data: 1.133465 - PINN: 0.016312\n","Loss over entire dataset: 0.000014\n","Epoch: 5000 - Loss: 1.159782 - Data: 1.143727 - PINN: 0.016055\n","Loss over entire dataset: 0.000045\n","Min loss:  1.1520854234695435\n"]}],"source":["#training the PINN N times\n","err_traj_x_5_32, err_traj_y_5_32, std_traj_x_5_32, std_traj_y_5_32 = compute_err_trajectory_conf(model_5_32, N)"]},{"cell_type":"code","execution_count":36,"metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1671488168995,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"xn5AwbR8xusd"},"outputs":[],"source":["x_err_conf.append(err_traj_x_5_32)\n","y_err_conf.append(err_traj_y_5_32)\n","x_std_conf.append(std_traj_x_5_32)\n","y_std_conf.append(std_traj_y_5_32)"]},{"cell_type":"markdown","metadata":{"id":"XgaSbBkox2B3"},"source":["hidden layers = 5 and neurons = 64"]},{"cell_type":"code","execution_count":38,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1671488209676,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"cPWwq4J1x7AN"},"outputs":[],"source":["#creating model \n","model_5_64 = NNApproximator(num_hidden=num_layer[1], dim_hidden=hidden_dim[2])"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1173340,"status":"ok","timestamp":1671489387496,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"BJpzK7h0yAI9","outputId":"7943b1dd-ceeb-46e3-b3fa-45bcba2ae21c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5007.938477 - Data: 15.788406 - PINN: 4992.149902\n","Loss over entire dataset: 0.013005\n","Epoch: 1000 - Loss: 3.635131 - Data: 3.089407 - PINN: 0.545724\n","Loss over entire dataset: 0.001814\n","Epoch: 2000 - Loss: 1.683103 - Data: 1.453594 - PINN: 0.229509\n","Loss over entire dataset: 0.000230\n","Epoch: 3000 - Loss: 1.519537 - Data: 1.404221 - PINN: 0.115316\n","Loss over entire dataset: 0.000191\n","Epoch: 4000 - Loss: 1.439825 - Data: 1.358536 - PINN: 0.081289\n","Loss over entire dataset: 0.000158\n","Epoch: 5000 - Loss: 1.464949 - Data: 1.400697 - PINN: 0.064252\n","Loss over entire dataset: 0.000196\n","Min loss:  1.3315587043762207\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.739513 - Data: 1.561568 - PINN: 0.177945\n","Loss over entire dataset: 0.289906\n","Epoch: 1000 - Loss: 1.304380 - Data: 1.253513 - PINN: 0.050867\n","Loss over entire dataset: 0.000080\n","Epoch: 2000 - Loss: 1.262962 - Data: 1.213628 - PINN: 0.049334\n","Loss over entire dataset: 0.000052\n","Epoch: 3000 - Loss: 1.230443 - Data: 1.185925 - PINN: 0.044519\n","Loss over entire dataset: 0.000037\n","Epoch: 4000 - Loss: 1.368237 - Data: 1.295661 - PINN: 0.072576\n","Loss over entire dataset: 0.000395\n","Epoch: 5000 - Loss: 1.190009 - Data: 1.157119 - PINN: 0.032890\n","Loss over entire dataset: 0.000022\n","Min loss:  1.1890065670013428\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.177984 - Data: 1.149691 - PINN: 0.028293\n","Loss over entire dataset: 0.215488\n","Epoch: 1000 - Loss: 1.173808 - Data: 1.146689 - PINN: 0.027119\n","Loss over entire dataset: 0.000017\n","Epoch: 2000 - Loss: 1.166670 - Data: 1.143158 - PINN: 0.023512\n","Loss over entire dataset: 0.000016\n","Epoch: 3000 - Loss: 1.163547 - Data: 1.141576 - PINN: 0.021971\n","Loss over entire dataset: 0.000016\n","Epoch: 4000 - Loss: 1.163101 - Data: 1.140542 - PINN: 0.022559\n","Loss over entire dataset: 0.000021\n","Epoch: 5000 - Loss: 1.167878 - Data: 1.147909 - PINN: 0.019969\n","Loss over entire dataset: 0.000010\n","Min loss:  1.1549873352050781\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.154825 - Data: 1.136667 - PINN: 0.018158\n","Loss over entire dataset: 0.106102\n","Epoch: 1000 - Loss: 1.156010 - Data: 1.137440 - PINN: 0.018570\n","Loss over entire dataset: 0.000011\n","Epoch: 2000 - Loss: 1.154642 - Data: 1.136500 - PINN: 0.018142\n","Loss over entire dataset: 0.000019\n","Epoch: 3000 - Loss: 1.150872 - Data: 1.134449 - PINN: 0.016422\n","Loss over entire dataset: 0.000012\n","Epoch: 4000 - Loss: 1.149847 - Data: 1.133943 - PINN: 0.015904\n","Loss over entire dataset: 0.000010\n","Epoch: 5000 - Loss: 1.157928 - Data: 1.139972 - PINN: 0.017956\n","Loss over entire dataset: 0.000025\n","Min loss:  1.1549381017684937\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.146916 - Data: 1.131974 - PINN: 0.014942\n","Loss over entire dataset: 0.089568\n","Epoch: 1000 - Loss: 1.147512 - Data: 1.131706 - PINN: 0.015806\n","Loss over entire dataset: 0.000012\n","Epoch: 2000 - Loss: 1.145090 - Data: 1.130690 - PINN: 0.014400\n","Loss over entire dataset: 0.000012\n","Epoch: 3000 - Loss: 1.144288 - Data: 1.130643 - PINN: 0.013645\n","Loss over entire dataset: 0.000012\n","Epoch: 4000 - Loss: 1.147075 - Data: 1.132731 - PINN: 0.014344\n","Loss over entire dataset: 0.000024\n","Epoch: 5000 - Loss: 1.142823 - Data: 1.129701 - PINN: 0.013122\n","Loss over entire dataset: 0.000011\n","Min loss:  1.1450848579406738\n"]}],"source":["#training the PINN N times\n","err_traj_x_5_64, err_traj_y_5_64, std_traj_x_5_64, std_traj_y_5_64 = compute_err_trajectory_conf(model_5_64, N)"]},{"cell_type":"code","execution_count":40,"metadata":{"executionInfo":{"elapsed":487,"status":"ok","timestamp":1671489422207,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"2hmjrSlr5nNa"},"outputs":[],"source":["x_err_conf.append(err_traj_x_5_64)\n","y_err_conf.append(err_traj_y_5_64)\n","x_std_conf.append(std_traj_x_5_64)\n","y_std_conf.append(std_traj_y_5_64)"]},{"cell_type":"markdown","metadata":{"id":"ifDChfwa1rH6"},"source":["hidden layers = 7 and neurons = 16"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":409,"status":"ok","timestamp":1671489469306,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"q0T9LQDj2G6c"},"outputs":[],"source":["#creating model \n","model_7_16 = NNApproximator(num_hidden=num_layer[2], dim_hidden=hidden_dim[0])"]},{"cell_type":"code","execution_count":43,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":770849,"status":"ok","timestamp":1671490296508,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"fbU20LZB2NX7","outputId":"ceb64e75-15d2-45e1-a8d1-5d4d756bd0be"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5009.409180 - Data: 11.972176 - PINN: 4997.437012\n","Loss over entire dataset: 0.011870\n","Epoch: 1000 - Loss: 5.527797 - Data: 4.203668 - PINN: 1.324129\n","Loss over entire dataset: 0.003030\n","Epoch: 2000 - Loss: 3.289555 - Data: 2.776554 - PINN: 0.513001\n","Loss over entire dataset: 0.001598\n","Epoch: 3000 - Loss: 1.748820 - Data: 1.525069 - PINN: 0.223750\n","Loss over entire dataset: 0.000314\n","Epoch: 4000 - Loss: 1.632604 - Data: 1.456432 - PINN: 0.176173\n","Loss over entire dataset: 0.000244\n","Epoch: 5000 - Loss: 1.547641 - Data: 1.414242 - PINN: 0.133400\n","Loss over entire dataset: 0.000204\n","Min loss:  1.4851361513137817\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.481306 - Data: 1.377363 - PINN: 0.103943\n","Loss over entire dataset: 0.069908\n","Epoch: 1000 - Loss: 1.454004 - Data: 1.359936 - PINN: 0.094069\n","Loss over entire dataset: 0.000161\n","Epoch: 2000 - Loss: 1.409209 - Data: 1.329936 - PINN: 0.079273\n","Loss over entire dataset: 0.000138\n","Epoch: 3000 - Loss: 1.360275 - Data: 1.294234 - PINN: 0.066041\n","Loss over entire dataset: 0.000110\n","Epoch: 4000 - Loss: 1.308846 - Data: 1.253843 - PINN: 0.055003\n","Loss over entire dataset: 0.000083\n","Epoch: 5000 - Loss: 1.275520 - Data: 1.222562 - PINN: 0.052957\n","Loss over entire dataset: 0.000076\n","Min loss:  1.2450391054153442\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.245165 - Data: 1.196001 - PINN: 0.049164\n","Loss over entire dataset: 0.050795\n","Epoch: 1000 - Loss: 1.236774 - Data: 1.188544 - PINN: 0.048230\n","Loss over entire dataset: 0.000039\n","Epoch: 2000 - Loss: 1.222829 - Data: 1.178043 - PINN: 0.044786\n","Loss over entire dataset: 0.000033\n","Epoch: 3000 - Loss: 1.223650 - Data: 1.175662 - PINN: 0.047988\n","Loss over entire dataset: 0.000047\n","Epoch: 4000 - Loss: 1.220691 - Data: 1.182304 - PINN: 0.038387\n","Loss over entire dataset: 0.000041\n","Epoch: 5000 - Loss: 1.190126 - Data: 1.155532 - PINN: 0.034594\n","Loss over entire dataset: 0.000023\n","Min loss:  1.186366319656372\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.182295 - Data: 1.149958 - PINN: 0.032337\n","Loss over entire dataset: 0.053031\n","Epoch: 1000 - Loss: 1.180034 - Data: 1.148902 - PINN: 0.031132\n","Loss over entire dataset: 0.000020\n","Epoch: 2000 - Loss: 1.176552 - Data: 1.146754 - PINN: 0.029798\n","Loss over entire dataset: 0.000019\n","Epoch: 3000 - Loss: 1.173911 - Data: 1.144979 - PINN: 0.028933\n","Loss over entire dataset: 0.000018\n","Epoch: 4000 - Loss: 1.171248 - Data: 1.143648 - PINN: 0.027600\n","Loss over entire dataset: 0.000016\n","Epoch: 5000 - Loss: 1.171293 - Data: 1.144686 - PINN: 0.026608\n","Loss over entire dataset: 0.000014\n","Min loss:  1.1765477657318115\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.202554 - Data: 1.169212 - PINN: 0.033342\n","Loss over entire dataset: 0.054558\n","Epoch: 1000 - Loss: 1.166010 - Data: 1.140416 - PINN: 0.025594\n","Loss over entire dataset: 0.000017\n","Epoch: 2000 - Loss: 1.164324 - Data: 1.139549 - PINN: 0.024774\n","Loss over entire dataset: 0.000017\n","Epoch: 3000 - Loss: 1.163517 - Data: 1.139564 - PINN: 0.023953\n","Loss over entire dataset: 0.000014\n","Epoch: 4000 - Loss: 1.161998 - Data: 1.138348 - PINN: 0.023650\n","Loss over entire dataset: 0.000016\n","Epoch: 5000 - Loss: 1.160738 - Data: 1.138124 - PINN: 0.022613\n","Loss over entire dataset: 0.000015\n","Min loss:  1.164318561553955\n"]}],"source":["#training the PINN N times\n","err_traj_x_7_16, err_traj_y_7_16, std_traj_x_7_16, std_traj_y_7_16 = compute_err_trajectory_conf(model_7_16, N)"]},{"cell_type":"code","execution_count":45,"metadata":{"executionInfo":{"elapsed":489,"status":"ok","timestamp":1671490330057,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"lRrZu5ZtBWkH"},"outputs":[],"source":["x_err_conf.append(err_traj_x_7_16)\n","y_err_conf.append(err_traj_y_7_16)\n","x_std_conf.append(std_traj_x_7_16)\n","y_std_conf.append(std_traj_y_7_16)"]},{"cell_type":"markdown","metadata":{"id":"cc5uCVLTBkDk"},"source":["hidden layers = 7 and neurons = 32"]},{"cell_type":"code","execution_count":47,"metadata":{"executionInfo":{"elapsed":1053,"status":"ok","timestamp":1671490350056,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"mdSTqhY7BlJ6"},"outputs":[],"source":["#creating model \n","model_7_32 = NNApproximator(num_hidden=num_layer[2], dim_hidden=hidden_dim[1])"]},{"cell_type":"code","execution_count":48,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":783351,"status":"ok","timestamp":1671491297544,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"0JdEVmYpBsvs","outputId":"5ecea0ad-a152-45f9-9be6-8fc18220341a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 4999.131348 - Data: 12.298479 - PINN: 4986.833008\n","Loss over entire dataset: 0.012152\n","Epoch: 1000 - Loss: 4.302918 - Data: 3.560537 - PINN: 0.742381\n","Loss over entire dataset: 0.002413\n","Epoch: 2000 - Loss: 2.165046 - Data: 1.848394 - PINN: 0.316652\n","Loss over entire dataset: 0.000640\n","Epoch: 3000 - Loss: 1.567306 - Data: 1.396364 - PINN: 0.170943\n","Loss over entire dataset: 0.000189\n","Epoch: 4000 - Loss: 1.471781 - Data: 1.355862 - PINN: 0.115919\n","Loss over entire dataset: 0.000161\n","Epoch: 5000 - Loss: 1.393024 - Data: 1.309388 - PINN: 0.083636\n","Loss over entire dataset: 0.000122\n","Min loss:  1.339711308479309\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.332730 - Data: 1.265374 - PINN: 0.067355\n","Loss over entire dataset: 0.067180\n","Epoch: 1000 - Loss: 1.306260 - Data: 1.243746 - PINN: 0.062514\n","Loss over entire dataset: 0.000076\n","Epoch: 2000 - Loss: 1.709245 - Data: 1.541595 - PINN: 0.167651\n","Loss over entire dataset: 0.000145\n","Epoch: 3000 - Loss: 1.259292 - Data: 1.199646 - PINN: 0.059645\n","Loss over entire dataset: 0.000041\n","Epoch: 4000 - Loss: 1.220504 - Data: 1.169447 - PINN: 0.051057\n","Loss over entire dataset: 0.000026\n","Epoch: 5000 - Loss: 1.191029 - Data: 1.147639 - PINN: 0.043390\n","Loss over entire dataset: 0.000015\n","Min loss:  1.1805403232574463\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.184165 - Data: 1.143863 - PINN: 0.040301\n","Loss over entire dataset: 0.106416\n","Epoch: 1000 - Loss: 1.178735 - Data: 1.139584 - PINN: 0.039151\n","Loss over entire dataset: 0.000013\n","Epoch: 2000 - Loss: 1.171155 - Data: 1.136000 - PINN: 0.035155\n","Loss over entire dataset: 0.000012\n","Epoch: 3000 - Loss: 1.224326 - Data: 1.169398 - PINN: 0.054928\n","Loss over entire dataset: 0.000038\n","Epoch: 4000 - Loss: 1.166606 - Data: 1.135506 - PINN: 0.031099\n","Loss over entire dataset: 0.000016\n","Epoch: 5000 - Loss: 1.184148 - Data: 1.148047 - PINN: 0.036102\n","Loss over entire dataset: 0.000062\n","Min loss:  1.1592960357666016\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.281474 - Data: 1.186726 - PINN: 0.094749\n","Loss over entire dataset: 0.065811\n","Epoch: 1000 - Loss: 1.753767 - Data: 1.685622 - PINN: 0.068145\n","Loss over entire dataset: 0.000437\n","Epoch: 2000 - Loss: 1.151863 - Data: 1.127673 - PINN: 0.024189\n","Loss over entire dataset: 0.000011\n","Epoch: 3000 - Loss: 1.149565 - Data: 1.126616 - PINN: 0.022949\n","Loss over entire dataset: 0.000011\n","Epoch: 4000 - Loss: 1.150108 - Data: 1.128499 - PINN: 0.021609\n","Loss over entire dataset: 0.000011\n","Epoch: 5000 - Loss: 1.177387 - Data: 1.152876 - PINN: 0.024511\n","Loss over entire dataset: 0.000020\n","Min loss:  1.151853322982788\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.317269 - Data: 1.255524 - PINN: 0.061746\n","Loss over entire dataset: 0.043054\n","Epoch: 1000 - Loss: 1.570470 - Data: 1.537405 - PINN: 0.033065\n","Loss over entire dataset: 0.000764\n","Epoch: 2000 - Loss: 1.171565 - Data: 1.123846 - PINN: 0.047719\n","Loss over entire dataset: 0.000009\n","Epoch: 3000 - Loss: 1.158934 - Data: 1.131726 - PINN: 0.027207\n","Loss over entire dataset: 0.000012\n","Epoch: 4000 - Loss: 1.147344 - Data: 1.126603 - PINN: 0.020741\n","Loss over entire dataset: 0.000008\n","Epoch: 5000 - Loss: 1.139421 - Data: 1.123188 - PINN: 0.016233\n","Loss over entire dataset: 0.000009\n","Min loss:  1.1480895280838013\n"]}],"source":["#training the PINN N times\n","err_traj_x_7_32, err_traj_y_7_32, std_traj_x_7_32, std_traj_y_7_32 = compute_err_trajectory_conf(model_7_32, N)"]},{"cell_type":"code","execution_count":49,"metadata":{"executionInfo":{"elapsed":506,"status":"ok","timestamp":1671491336583,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"oPUirn77FQsC"},"outputs":[],"source":["x_err_conf.append(err_traj_x_7_32)\n","y_err_conf.append(err_traj_y_7_32)\n","x_std_conf.append(std_traj_x_7_32)\n","y_std_conf.append(std_traj_y_7_32)"]},{"cell_type":"markdown","metadata":{"id":"yuginPp4FZkE"},"source":["hidden layers = 7 and neurons = 64"]},{"cell_type":"code","execution_count":51,"metadata":{"executionInfo":{"elapsed":436,"status":"ok","timestamp":1671491357999,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"B2NngvMaFaMX"},"outputs":[],"source":["#creating model \n","model_7_64 = NNApproximator(num_hidden=num_layer[2], dim_hidden=hidden_dim[2])"]},{"cell_type":"code","execution_count":52,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":658218,"status":"ok","timestamp":1671492843134,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"OzuYsoYrFhbz","outputId":"1f9b50cb-54f0-4727-db0d-f322001d5c27"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using Adam optimizer ... \n","Epoch: 0 - Loss: 5011.499023 - Data: 19.891182 - PINN: 4991.607910\n","Loss over entire dataset: 0.015523\n","Epoch: 1000 - Loss: 17.542192 - Data: 16.771872 - PINN: 0.770321\n","Loss over entire dataset: 0.005145\n","Epoch: 2000 - Loss: 1.714890 - Data: 1.477640 - PINN: 0.237251\n","Loss over entire dataset: 0.000280\n","Epoch: 3000 - Loss: 1.612304 - Data: 1.440727 - PINN: 0.171576\n","Loss over entire dataset: 0.000242\n","Epoch: 4000 - Loss: 1.534532 - Data: 1.391942 - PINN: 0.142589\n","Loss over entire dataset: 0.000198\n","Epoch: 5000 - Loss: 1.428625 - Data: 1.323455 - PINN: 0.105170\n","Loss over entire dataset: 0.000141\n","Min loss:  1.3575477600097656\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.724043 - Data: 1.419495 - PINN: 0.304549\n","Loss over entire dataset: 0.250291\n","Epoch: 1000 - Loss: 1.330644 - Data: 1.256859 - PINN: 0.073785\n","Loss over entire dataset: 0.000085\n","Epoch: 2000 - Loss: 1.424352 - Data: 1.248162 - PINN: 0.176190\n","Loss over entire dataset: 0.000051\n","Epoch: 3000 - Loss: 1.276904 - Data: 1.206333 - PINN: 0.070571\n","Loss over entire dataset: 0.000406\n","Epoch: 4000 - Loss: 1.234701 - Data: 1.180286 - PINN: 0.054414\n","Loss over entire dataset: 0.000051\n","Epoch: 5000 - Loss: 1.212858 - Data: 1.158937 - PINN: 0.053921\n","Loss over entire dataset: 0.000020\n","Min loss:  1.1999000310897827\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.331175 - Data: 1.172900 - PINN: 0.158274\n","Loss over entire dataset: 0.132951\n","Epoch: 1000 - Loss: 1.207453 - Data: 1.160261 - PINN: 0.047192\n","Loss over entire dataset: 0.000059\n","Epoch: 2000 - Loss: 1.272738 - Data: 1.213583 - PINN: 0.059156\n","Loss over entire dataset: 0.000091\n","Epoch: 3000 - Loss: 1.229386 - Data: 1.160141 - PINN: 0.069245\n","Loss over entire dataset: 0.000061\n","Epoch: 4000 - Loss: 1.186279 - Data: 1.141897 - PINN: 0.044381\n","Loss over entire dataset: 0.000008\n","Epoch: 5000 - Loss: 1.314404 - Data: 1.196494 - PINN: 0.117910\n","Loss over entire dataset: 0.000796\n","Min loss:  1.1666877269744873\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 2.649932 - Data: 1.605597 - PINN: 1.044335\n","Loss over entire dataset: 0.148720\n","Epoch: 1000 - Loss: 1.235250 - Data: 1.180092 - PINN: 0.055157\n","Loss over entire dataset: 0.000114\n","Epoch: 2000 - Loss: 1.185903 - Data: 1.124404 - PINN: 0.061499\n","Loss over entire dataset: 0.000011\n","Epoch: 3000 - Loss: 1.153905 - Data: 1.127219 - PINN: 0.026686\n","Loss over entire dataset: 0.000008\n","Epoch: 4000 - Loss: 2.001592 - Data: 1.935517 - PINN: 0.066074\n","Loss over entire dataset: 0.000644\n","Epoch: 5000 - Loss: 1.163117 - Data: 1.135362 - PINN: 0.027755\n","Loss over entire dataset: 0.000027\n","Min loss:  1.1567695140838623\n","Using Adam optimizer ... \n","Epoch: 0 - Loss: 1.688009 - Data: 1.277775 - PINN: 0.410234\n","Loss over entire dataset: 0.051203\n","Epoch: 1000 - Loss: 1.146564 - Data: 1.125719 - PINN: 0.020845\n","Loss over entire dataset: 0.000009\n","Epoch: 2000 - Loss: 1.144027 - Data: 1.124874 - PINN: 0.019152\n","Loss over entire dataset: 0.000010\n","Epoch: 3000 - Loss: 1.143894 - Data: 1.123231 - PINN: 0.020663\n","Loss over entire dataset: 0.000010\n","Epoch: 4000 - Loss: 1.230214 - Data: 1.207023 - PINN: 0.023192\n","Loss over entire dataset: 0.000128\n","Epoch: 5000 - Loss: 1.151619 - Data: 1.132120 - PINN: 0.019499\n","Loss over entire dataset: 0.000031\n","Min loss:  1.1439951658248901\n"]}],"source":["#training the PINN N times\n","err_traj_x_7_64, err_traj_y_7_64, std_traj_x_7_64, std_traj_y_7_64 = compute_err_trajectory_conf(model_7_64, N)"]},{"cell_type":"code","execution_count":53,"metadata":{"executionInfo":{"elapsed":1061,"status":"ok","timestamp":1671492858908,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"cscV66Y3NQRE"},"outputs":[],"source":["x_err_conf.append(err_traj_x_7_64)\n","y_err_conf.append(err_traj_y_7_64)\n","x_std_conf.append(std_traj_x_7_64)\n","y_std_conf.append(std_traj_y_7_64)"]},{"cell_type":"markdown","metadata":{"id":"cvcVLrpmNoOs"},"source":["Save data and export"]},{"cell_type":"code","execution_count":55,"metadata":{"executionInfo":{"elapsed":10248,"status":"ok","timestamp":1671492938437,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"Zl8iV1BsNnnB"},"outputs":[],"source":["#converting to numpy array\n","x_err_conf_train = np.asarray(x_err_conf)\n","y_err_conf_train = np.asarray(y_err_conf)\n","x_std_conf_train = np.asarray(x_std_conf)\n","y_std_conf_train = np.asarray(y_std_conf)\n","\n","#saving numpy array \n","np.save('x_err_conf_multi_train', x_err_conf_train)\n","np.save('y_err_conf_multi_train', y_err_conf_train)\n","np.save('x_std_conf_multi_train', x_std_conf_train)\n","np.save('y_std_conf_multi_train', y_std_conf_train)\n"]},{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":839,"status":"ok","timestamp":1671492964586,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"e25Jj_Mrvk_9","outputId":"710fec31-7c2f-4fbc-81dd-a30a29e46aba"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00057774 0.00115376 0.00043045 0.00124472 0.00064328 0.00270663\n"," 0.00059773 0.00082208 0.00389709]\n"]}],"source":["print(x_err_conf_train)"]},{"cell_type":"code","execution_count":73,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":321,"status":"ok","timestamp":1671452640389,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"OABdfg0jNu2_","outputId":"75034143-ada1-4adf-c9ef-805aee2b604d"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00049074 0.00024972 0.00849996 0.00374048 0.0011209  0.00028189\n"," 0.00283479 0.00103393 0.00150859]\n"]}],"source":["print(x_err_conf_train)"]},{"cell_type":"code","execution_count":58,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1038,"status":"ok","timestamp":1671492991095,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"dq8TRFepvuo1","outputId":"66449be7-3b38-4ce5-f4dd-e824737b8227"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00896326 0.0043567  0.01191031 0.02272385 0.01264716 0.04593218\n"," 0.00867561 0.014009   0.01737641]\n"]}],"source":["print(y_err_conf_train)"]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":231,"status":"ok","timestamp":1671452643831,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"ePKZ3MJxNzE5","outputId":"1997759a-dccc-49f3-82d8-9f72cc7a68c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.0025165  0.0032034  0.03080785 0.04365365 0.03268663 0.0032748\n"," 0.08341615 0.06028629 0.09108653]\n"]}],"source":["print(y_err_conf_train)"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":515,"status":"ok","timestamp":1671493023037,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"nXvLmVijS6NN","outputId":"41818529-76c1-4511-cc47-33264a2a3d9e"},"outputs":[{"name":"stdout","output_type":"stream","text":["nb hidden layers 3 and nb neurons 16:\n","mean squared error in x-axis:0.00058\n","mean squared error in y-axis:0.00896\n","std of mean squared error in x-axis:0.00018\n","std of mean squared error in y-axis:0.01229\n",".........\n","nb hidden layers 3 and nb neurons 32:\n","mean squared error in x-axis:0.00115\n","mean squared error in y-axis:0.00436\n","std of mean squared error in x-axis:0.00044\n","std of mean squared error in y-axis:0.00143\n",".........\n","nb hidden layers 3 and nb neurons 64:\n","mean squared error in x-axis:0.00043\n","mean squared error in y-axis:0.01191\n","std of mean squared error in x-axis:0.00016\n","std of mean squared error in y-axis:0.01364\n",".........\n","nb hidden layers 5 and nb neurons 16:\n","mean squared error in x-axis:0.00124\n","mean squared error in y-axis:0.02272\n","std of mean squared error in x-axis:0.00046\n","std of mean squared error in y-axis:0.01517\n",".........\n","nb hidden layers 5 and nb neurons 32:\n","mean squared error in x-axis:0.00064\n","mean squared error in y-axis:0.01265\n","std of mean squared error in x-axis:0.00023\n","std of mean squared error in y-axis:0.0194\n",".........\n","nb hidden layers 5 and nb neurons 64:\n","mean squared error in x-axis:0.00271\n","mean squared error in y-axis:0.04593\n","std of mean squared error in x-axis:0.00132\n","std of mean squared error in y-axis:0.03473\n",".........\n","nb hidden layers 7 and nb neurons 16:\n","mean squared error in x-axis:0.0006\n","mean squared error in y-axis:0.00868\n","std of mean squared error in x-axis:0.00033\n","std of mean squared error in y-axis:0.00486\n",".........\n","nb hidden layers 7 and nb neurons 32:\n","mean squared error in x-axis:0.00082\n","mean squared error in y-axis:0.01401\n","std of mean squared error in x-axis:0.00048\n","std of mean squared error in y-axis:0.00928\n",".........\n","nb hidden layers 7 and nb neurons 64:\n","mean squared error in x-axis:0.0039\n","mean squared error in y-axis:0.01738\n","std of mean squared error in x-axis:0.00459\n","std of mean squared error in y-axis:0.00588\n",".........\n"]}],"source":["import math\n","for i in range(9):\n","    print('nb hidden layers '+str(num_layer[i//3])+' and nb neurons '+str(hidden_dim[i%3])+':')\n","    print('mean squared error in x-axis:' + str(round(x_err_conf_train[i],5)))\n","    print('mean squared error in y-axis:' + str(round(y_err_conf_train[i],5)))\n","    print('std of mean squared error in x-axis:' + str(round(x_std_conf_train[i],5)))\n","    print('std of mean squared error in y-axis:' + str(round(y_std_conf_train[i],5)))\n","    print('.........')"]},{"cell_type":"markdown","metadata":{"id":"d_mM44NajjYC"},"source":["Compute and print the mean error for each hyperparameters combination :"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1236,"status":"ok","timestamp":1671493069325,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"NUJIYL_SVXSM","outputId":"c1d01f86-80a9-4838-ee73-75435b0c5625"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.0047705  0.00275523 0.00617038 0.01198428 0.00664522 0.02431941\n"," 0.00463667 0.00741554 0.01063675]\n"]}],"source":["err_traj = 0.5*(x_err_conf_train+y_err_conf_train)\n","print(err_traj)"]},{"cell_type":"markdown","metadata":{"id":"vJsQET1oj0Tf"},"source":["Choose the combination with the lowest error : "]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":418,"status":"ok","timestamp":1671493072401,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"8H82wv0vTlFp","outputId":"3e499ea8-174c-4417-f179-839c4f275373"},"outputs":[{"name":"stdout","output_type":"stream","text":["the lowest error is obtain with 3 hidden layer and 32 neurons with a mean squared error of 0.0027552268552429454\n"]}],"source":["best_conf = np.argmin(err_traj)\n","print('the lowest error is obtain with '+str(num_layer[best_conf//3])+ ' hidden layer'+' and '+str(hidden_dim[best_conf%3])+' neurons'+' with a mean squared error of '+str(err_traj[best_conf]))"]},{"cell_type":"code","execution_count":62,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":979,"status":"ok","timestamp":1671493430109,"user":{"displayName":"albias havolli","userId":"13039241438363088387"},"user_tz":-60},"id":"lfagzROrxNOn","outputId":"82e4b6f8-f01e-48ff-9143-d7df9fe62d9f"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.00623241 0.00093159 0.00690351 0.00781494 0.00981656 0.01802698\n"," 0.00259372 0.00487926 0.00523886]\n"]}],"source":["std_err_traj = 0.5*(x_std_conf_train+y_std_conf_train)\n","print(std_err_traj)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMaDe5v8GZGUSMLKY91TeWh","provenance":[]},"gpuClass":"premium","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
