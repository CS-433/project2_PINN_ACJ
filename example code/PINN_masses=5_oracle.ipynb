{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install functorch\n",
        "print(\"--> Restarting colab instance\") \n",
        "get_ipython().kernel.do_shutdown(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_cCIVKBSTTY",
        "outputId": "c524b9a1-ff74-4e74-a3a5-657666ef34e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting functorch\n",
            "  Downloading functorch-1.13.0-py2.py3-none-any.whl (2.1 kB)\n",
            "Collecting torch<1.13.1,>=1.13.0\n",
            "  Downloading torch-1.13.0-cp38-cp38-manylinux1_x86_64.whl (890.2 MB)\n",
            "\u001b[K     |██████████████████████████████  | 834.1 MB 1.2 MB/s eta 0:00:46tcmalloc: large alloc 1147494400 bytes == 0x65c10000 @  0x7f94385f6615 0x5d631c 0x51e4f1 0x51e67b 0x4f7585 0x49ca7c 0x4fdff5 0x49caa1 0x4fdff5 0x49ced5 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x4f60a9 0x55f926 0x5d7c18 0x5d9412 0x586636 0x5d813c 0x55f3fd 0x55e571 0x5d7cf1 0x49ced5 0x55e571 0x5d7cf1 0x49ec69 0x5d7c18 0x49ca7c 0x4fdff5 0x49ced5\n",
            "\u001b[K     |████████████████████████████████| 890.2 MB 5.2 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<1.13.1,>=1.13.0->functorch) (4.1.1)\n",
            "Collecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 557.1 MB 12 kB/s \n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 317.1 MB 35 kB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 61.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.13.1,>=1.13.0->functorch) (0.38.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch<1.13.1,>=1.13.0->functorch) (57.4.0)\n",
            "Installing collected packages: nvidia-cublas-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, torch, functorch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchtext 0.13.1 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\n",
            "Successfully installed functorch-1.13.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0\n",
            "--> Restarting colab instance\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'status': 'ok', 'restart': True}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdE9ShALJfLU"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from scipy.integrate import solve_ivp\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "BGu8reYjGtCX"
      },
      "outputs": [],
      "source": [
        "from functorch import vmap, vjp\n",
        "from functorch import jacrev, jacfwd\n",
        "\n",
        "# class NNApproximator(nn.Module):\n",
        "#   def __init__(self, dim_input = 1, dim_output = 2, num_hidden = 2, dim_hidden = 1, activation=nn.Tanh()):\n",
        "#     super().__init__()\n",
        "\n",
        "#     self.layer_in = nn.Linear(dim_input, dim_hidden)\n",
        "#     self.layer_out = nn.Linear(dim_hidden, dim_output)\n",
        "#     # self.A = nn.Parameter(torch.randn(2,2))\n",
        "#     self.k = nn.Parameter(torch.rand(1, requires_grad=True))\n",
        "#     # self.A = self.k * torch.from_numpy(np.array([[-1,1],[1,-1]]))\n",
        "\n",
        "#     num_middle = num_hidden - 1\n",
        "#     self.middle_layers = nn.ModuleList(\n",
        "#         [nn.Linear(dim_hidden, dim_hidden) for _ in range(num_middle)]\n",
        "#     )\n",
        "#     self.activation = activation\n",
        "\n",
        "#   def forward(self, x):\n",
        "#     out = self.activation(self.layer_in(x))\n",
        "#     for layer in self.middle_layers:\n",
        "#       out = self.activation(layer(out))\n",
        "#     return self.layer_out(out)\n",
        "\n",
        "#   # reference for implementing derivatives for batched inputs\n",
        "#   # https://pytorch.org/functorch/stable/notebooks/jacobians_hessians.html\n",
        "#   def jacobian(self, x):\n",
        "#     jac = vmap(jacrev(self.forward))\n",
        "#     return jac(x).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RvyrVlPSPxu"
      },
      "outputs": [],
      "source": [
        "class NNOracle(nn.Module):\n",
        "  def __init__(self, dim_input = 6, dim_output = 2):\n",
        "    super().__init__()\n",
        "\n",
        "    self.k = 50.0\n",
        "    self.g = torch.from_numpy(np.array([[0, -9.81]]))\n",
        "    self.L0 = 5.0\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = x[:2]\n",
        "    x2 = x[2:4]\n",
        "    x3 = x[4:]\n",
        "    dx1 = x2 - x1\n",
        "    dx2 = x3 - x2\n",
        "    dx1_norm = torch.sqrt(torch.sum(dx1 ** 2))\n",
        "    dx2_norm = torch.sqrt(torch.sum(dx2 ** 2))\n",
        "    f1 = -self.k * (dx1_norm - self.L0) * (dx1 / dx1_norm)\n",
        "    f2 = self.k * (dx2_norm - self.L0) * (dx2 / dx2_norm)\n",
        "    return self.g + f1 + f2\n",
        "\n",
        "  def jacobian(self, x):\n",
        "    jac = vmap(jacrev(self.forward))\n",
        "    return jac(x).squeeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khDNqG3bSPx1"
      },
      "outputs": [],
      "source": [
        "def compute_data_loss(model, x_tr, y_tr):\n",
        "  return 0.5 * torch.mean((model.forward(x_tr) - y_tr) ** 2)\n",
        "\n",
        "def compute_PINN_loss(model, x, k):\n",
        "    F_dot = model.jacobian(x)\n",
        "    s1 = x[:, 0:2] - x[:, 2:4]\n",
        "    s2 = x[:, 4:6] - x[:, 2:4]\n",
        "\n",
        "    s1rot = s1 @ torch.from_numpy(np.array([[0, -1], [1, 0]]).T).float()\n",
        "    s2rot = s2 @ torch.from_numpy(np.array([[0, -1], [1, 0]]).T).float()\n",
        "\n",
        "    f1_constr = torch.norm(torch.einsum('ijk,ik->ij', F_dot[:, :, 0:2], s1), dim=1) / torch.norm(s1, dim=1)\n",
        "    f2_constr = torch.norm(torch.einsum('ijk,ik->ij', F_dot[:, :, 4:6], s2), dim=1) / torch.norm(s2, dim=1)\n",
        "\n",
        "    f1_perp = torch.einsum('ijk,ik->ij', F_dot[:, :, 0:2], s1rot) / (torch.norm(s1, dim=1) ** 2)[:, None]\n",
        "    # print(f1_perp.shape)\n",
        "    # print(torch.norm(s1, dim=1).shape)\n",
        "    f2_perp = torch.einsum('ijk,ik->ij', F_dot[:, :, 4:6], s2rot) / (torch.norm(s2, dim=1) ** 2)[:, None]\n",
        "\n",
        "    f1_perp = torch.einsum(\"ij,ik->i\", f1_perp, s1)\n",
        "    f2_perp = torch.einsum('ij,ik->i', f2_perp, s2)\n",
        "\n",
        "    print(f1_constr)\n",
        "    print(f2_constr)\n",
        "    print(f1_perp)\n",
        "    print(f2_perp)\n",
        "    \n",
        "    return ((k - f1_constr) ** 2).mean() + ((k - f2_constr) ** 2).mean() + (f1_perp ** 2).mean() + (f2_perp ** 2).mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgcwZluQSPx6",
        "outputId": "debdadd0-84d1-446d-f8f1-9452b1e1a64b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[-215.8301,   49.9283,  576.3270, -517.4025, -360.4968,  467.4741],\n",
            "         [  49.9284,   40.6224, -517.4025,  441.7377,  467.4741, -482.3601]],\n",
            "\n",
            "        [[-501.8471,  -83.9989,  741.0087,  -79.9194, -239.1616,  163.9182],\n",
            "         [ -83.9989,   37.2142,  -79.9194,    5.7067,  163.9182,  -42.9209]]],\n",
            "       grad_fn=<SqueezeBackward0>)\n"
          ]
        }
      ],
      "source": [
        "model = NNOracle()\n",
        "\n",
        "Nt = 2\n",
        "x = torch.rand(Nt, 6, requires_grad=True)\n",
        "# print(x)\n",
        "print(model.jacobian(x))\n",
        "# print(compute_PINN_loss(model, x, model.k))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# x = torch.from_numpy(np.array([[0,0, 2,0, 3,2]])).float().requires_grad_()\n",
        "x = torch.rand(size=(1,6), requires_grad=True)\n",
        "\n",
        "F_dot = model.jacobian(x).detach()\n",
        "F_dot_2 = F_dot[:,4:]\n",
        "eigval, eigvec = torch.linalg.eig(F_dot_2)\n",
        "eigvec = eigvec / eigvec[0,1]\n",
        "# print(eigval)\n",
        "# print(eigvec)\n",
        "\n",
        "s2 = x[:, 4:6] - x[:, 2:4]\n",
        "s2 = s2 / torch.norm(s2,dim=1)\n",
        "print(\"This should be equal to k: \", s2 @ F_dot_2 @ s2.T - model.k)\n",
        "print(\"This should be equal to k: \", s2.squeeze().reshape(2,1).T @ F_dot_2 @ s2.squeeze().reshape(2,1) - model.k)\n",
        "\n",
        "s2rot = s2 @ torch.from_numpy(np.array([[0, -1], [1, 0]]).T).float().detach()\n",
        "print(\"This should be zero...?\", s2 @ F_dot_2 @ s2rot.T)\n",
        "print(\"This should be zero...?\", s2.squeeze().reshape(2,1).T @ F_dot_2 @ s2rot.squeeze().reshape(2,1))\n",
        "\n",
        "print(s2.squeeze())\n",
        "print(s2rot.squeeze())\n",
        "print(F_dot_2.squeeze())\n"
      ],
      "metadata": {
        "id": "fti5R_DkUOK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "408c12c6-f019-43d8-d917-0de6d30e242a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This should be equal to k:  tensor([[-6.8665e-05]], grad_fn=<SubBackward0>)\n",
            "This should be equal to k:  tensor([[-6.8665e-05]], grad_fn=<SubBackward0>)\n",
            "This should be zero...? tensor([[9.5367e-07]], grad_fn=<MmBackward0>)\n",
            "This should be zero...? tensor([[7.1384e-07]], grad_fn=<MmBackward0>)\n",
            "tensor([0.9762, 0.2167], grad_fn=<SqueezeBackward0>)\n",
            "tensor([-0.2167,  0.9762], grad_fn=<SqueezeBackward0>)\n",
            "tensor([[  25.9062,  108.5577],\n",
            "        [ 108.5577, -439.1210]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "myF = F_dot[None,:,:]\n",
        "\n",
        "print(s2.squeeze())\n",
        "print(s2rot.squeeze())\n",
        "print(myF[:,:,4:].squeeze())\n",
        "\n",
        "print(torch.einsum('ik, ijk, ij->i', s2, myF[:,:,4:], s2) - model.k)\n",
        "print(torch.einsum('ij, ijk, ik->i', s2, myF[:,:,4:], s2) - model.k)\n",
        "print(torch.einsum('ik, ikj, ij->i', s2, myF[:,:,4:], s2) - model.k)\n",
        "print(torch.einsum('ij, ikj, ik->i', s2, myF[:,:,4:], s2) - model.k)\n",
        "\n",
        "print(torch.einsum('ik, ijk, ij->i', s2, myF[:,:,4:], s2rot))\n",
        "print(torch.einsum('ij, ijk, ik->i', s2, myF[:,:,4:], s2rot))\n",
        "print(torch.einsum('ik, ikj, ij->i', s2, myF[:,:,4:], s2rot))\n",
        "print(torch.einsum('ij, ikj, ik->i', s2, myF[:,:,4:], s2rot))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWMeeFkjyU4l",
        "outputId": "728a8652-037e-4e61-c532-36150b7b7a74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.6361,  0.7716], grad_fn=<SqueezeBackward0>)\n",
            "tensor([-0.7716, -0.6361], grad_fn=<SqueezeBackward0>)\n",
            "tensor([[-180.0462, -189.6644],\n",
            "        [-189.6644, -106.3712]])\n",
            "tensor([2.2888e-05], grad_fn=<SubBackward0>)\n",
            "tensor([2.2888e-05], grad_fn=<SubBackward0>)\n",
            "tensor([2.2888e-05], grad_fn=<SubBackward0>)\n",
            "tensor([2.2888e-05], grad_fn=<SubBackward0>)\n",
            "tensor([5.7220e-06], grad_fn=<ViewBackward0>)\n",
            "tensor([-1.5259e-05], grad_fn=<ViewBackward0>)\n",
            "tensor([-1.5259e-05], grad_fn=<ViewBackward0>)\n",
            "tensor([5.7220e-06], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "gc_course_env",
      "language": "python",
      "name": "gc_course_env"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}